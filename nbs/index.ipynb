{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from MediaMinder.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MediaMinder\n",
    "\n",
    "> Media Monitoring Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project demonstrates a simple AI agent app that performs media monitoring and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "\n",
    "Given a company of interest, we want to gather recent content about that company and extract\n",
    "relevant information such as company divisions, products, events, people, sentiments, etc. Use\n",
    "cases for this type of monitoring include:\n",
    "\n",
    "- Investing: identify signals that may affect stock price\n",
    "\n",
    "- Marketing: determine customer sentiment\n",
    "\n",
    "- Public Relation: Measure success of public relations campaigns\n",
    "\n",
    "## Existing Solutions\n",
    "\n",
    "There are a number of companies that do this work. There are a number of challenges working with them:\n",
    "\n",
    "- Lack of depth finding results: often they need to be seeded with a known set of sites and publications\n",
    "\n",
    "- Lack of support for content that is not written in English\n",
    "\n",
    "- Need to use booleans to filter out unrelated results with the same names\n",
    "\n",
    "# The promise of LLMs\n",
    "\n",
    "- Can define search and filter criteria in plain English\n",
    "\n",
    "- Can deal with non-English content reasonably well\n",
    "\n",
    "# The promise of Agents\n",
    "\n",
    "- Can define agents that perform specific media analysis tasks and combine their behavior\n",
    "  to get more intelligent responses\n",
    "\n",
    "# Challenges of Agents (right now)\n",
    "\n",
    "- Most open source LLMs do not reliably use tools to perform tasks, so you need to use\n",
    "  a model like GPT-4\n",
    "\n",
    "- Agents can generate a huge number of tokens, so running them can be expensive\n",
    "\n",
    "- Because of the large amount of tokens generated, agents can be a lot slower than\n",
    "  other approaches, especially if there is a specific, well-defined workflow to\n",
    "  perform a task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "### Project\n",
    "\n",
    "Install the project dependencies by running\n",
    "\n",
    "```sh\n",
    "poetry install\n",
    "```\n",
    "\n",
    "### SearXNG\n",
    "\n",
    "We use SearXNG to provide web and news search capabilities. It is easiest to run this via Docker container.\n",
    "\n",
    "First, pull the repo:\n",
    "\n",
    "```sh\n",
    "docker pull searxng/searxng\n",
    "```\n",
    "\n",
    "Then run it thusly:\n",
    "\n",
    "```sh\n",
    "docker run -it \\\n",
    "    -d -p 8080:8080 \\\n",
    "    -v \"${PWD}/searxng:/etc/searxng\" \\\n",
    "    -e \"BASE_URL=http://localhost:8080/\" \\\n",
    "    -e \"INSTANCE_NAME=my-instance\" \\\n",
    "    searxng/searxng\n",
    "```\n",
    "\n",
    "### Ollama\n",
    "\n",
    "If you want to use Ollama to run this locally, pull the Llama3 model:\n",
    "\n",
    "```sh\n",
    "ollama pull llama3`\n",
    "```\n",
    "\n",
    "Then create the custom model:\n",
    "\n",
    "```sh\n",
    "ollama create crewai-llama3:8b -f ./Modelfile-llama3\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run from the command line, run:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "python analyze.py [NAME-OF-COMPANY]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
